"use strict";(self.webpackChunksiglens_docs=self.webpackChunksiglens_docs||[]).push([[873],{1561:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});var t=s(5893),i=s(1151);const a={},o="Benchmark Against ClickHouse",r={id:"benchmarks/nyc-taxi-benchmark-runbook",title:"Benchmark Against ClickHouse",description:"Common setup",source:"@site/docs/benchmarks/nyc-taxi-benchmark-runbook.md",sourceDirName:"benchmarks",slug:"/benchmarks/nyc-taxi-benchmark-runbook",permalink:"/siglens-docs/benchmarks/nyc-taxi-benchmark-runbook",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{}},l={},c=[{value:"Common setup",id:"common-setup",level:2},{value:"Making the dataset",id:"making-the-dataset",level:2},{value:"Benchmark SigLens",id:"benchmark-siglens",level:2},{value:"Install Go",id:"install-go",level:3},{value:"Clone SigLens",id:"clone-siglens",level:3},{value:"Enable AgileAggs",id:"enable-agileaggs",level:3},{value:"Start SigLens",id:"start-siglens",level:3},{value:"Setup PQS",id:"setup-pqs",level:3},{value:"Setup an ingestion script",id:"setup-an-ingestion-script",level:3},{value:"Ingest the data into SigLens",id:"ingest-the-data-into-siglens",level:3},{value:"Restart SigLens",id:"restart-siglens",level:3},{value:"View Logs",id:"view-logs",level:3},{value:"Run the Queries in SigLens",id:"run-the-queries-in-siglens",level:3},{value:"Benchmark ClickHouse",id:"benchmark-clickhouse",level:2},{value:"Install ClickHouse",id:"install-clickhouse",level:3},{value:"Configure the ClickHouse data folder",id:"configure-the-clickhouse-data-folder",level:3},{value:"Run ClickHouse",id:"run-clickhouse",level:3},{value:"Make the ClickHouse Table",id:"make-the-clickhouse-table",level:3},{value:"Ingest the Data",id:"ingest-the-data",level:3},{value:"Run the Queries in ClickHouse",id:"run-the-queries-in-clickhouse",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"benchmark-against-clickhouse",children:"Benchmark Against ClickHouse"}),"\n",(0,t.jsx)(n.h2,{id:"common-setup",children:"Common setup"}),"\n",(0,t.jsx)(n.p,{children:"Setup a server to run the benchmarks.\nI used an AWS im4gn.2xlarge running Ubuntu 22.04.\nThis instance has 8 vCPUs, 32 GB of RAM, and 3.5 TB of storage, but you have to mount the storage with the following steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"ssh into your server"}),"\n",(0,t.jsxs)(n.li,{children:["Run ",(0,t.jsx)(n.code,{children:"lsblk"})," and you should see something like the following, with the ",(0,t.jsx)(n.code,{children:"nvme1n1"})," item having 3.4 TB of storage."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nloop0          7:0    0  21.3M  1 loop /snap/amazon-ssm-agent/7529\nloop1          7:1    0  49.1M  1 loop /snap/core18/2794\nloop2          7:2    0  59.3M  1 loop /snap/core20/2019\nloop3          7:3    0 109.6M  1 loop /snap/lxd/24326\nloop4          7:4    0  35.5M  1 loop /snap/snapd/20102\nnvme0n1      259:0    0     8G  0 disk\n\u251c\u2500nvme0n1p1  259:2    0   7.9G  0 part /\n\u2514\u2500nvme0n1p15 259:3    0    99M  0 part /boot/efi\nnvme1n1      259:1    0   3.4T  0 disk\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Mount the storage"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo mkfs.xfs /dev/nvme1n1\nsudo mkdir /mnt/nvme1n1\nsudo mount /dev/nvme1n1 /mnt/nvme1n1\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsxs)(n.li,{children:["You can check that it's mounted by running ",(0,t.jsx)(n.code,{children:"df -h"})," and you should see something like this:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Filesystem       Size  Used Avail Use% Mounted on\n/dev/root        7.6G  1.5G  6.2G  20% /\ntmpfs             16G     0   16G   0% /dev/shm\ntmpfs            6.2G  948K  6.2G   1% /run\ntmpfs            5.0M     0  5.0M   0% /run/lock\n/dev/nvme0n1p15   98M  6.3M   92M   7% /boot/efi\ntmpfs            3.1G  4.0K  3.1G   1% /run/user/1000\n/dev/nvme1n1     3.5T   25G  3.4T   1% /mnt/nvme1n1\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"5",children:["\n",(0,t.jsx)(n.li,{children:"Update permissions"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd /mnt/nvme1n1\nsudo chmod 777 .\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"6",children:["\n",(0,t.jsx)(n.li,{children:"Configure AWS CLI"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo apt-get install awscli -y\naws configure\n"})}),"\n",(0,t.jsx)(n.h2,{id:"making-the-dataset",children:"Making the dataset"}),"\n",(0,t.jsxs)(n.p,{children:["Make a ",(0,t.jsx)(n.code,{children:"data/"})," directory to store the data, then go to ",(0,t.jsx)(n.a,{href:"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page",children:"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"})," and download the data.\nI used the 2011-2017 yellow taxi trip parquet files.\nNext, you need to convert the parquet files to TSV."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd data\npython -m venv taxis\nsource taxis/bin/activate\npip install pandas pyarrow\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Make a file ",(0,t.jsx)(n.code,{children:"parquet_to_tsv.py"})," with the following content."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"import pandas as pd\nimport glob\nimport os\nimport sys\n\ndef convert_parquet_to_tsv(input_directory, output_directory):\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n\n    for parquet_file in glob.glob(os.path.join(input_directory, '*.parquet')):\n        df = pd.read_parquet(parquet_file)\n        base_name = os.path.basename(parquet_file)\n        tsv_file = os.path.join(output_directory, base_name.replace('.parquet', '.tsv'))\n        df.to_csv(tsv_file, sep='\\t', index=False)\n        print(f\"Converted {parquet_file} to {tsv_file}\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) != 3:\n        print(\"Usage: python script.py <input_directory> <output_directory>\")\n        sys.exit(1)\n\n    input_dir = sys.argv[1]\n    output_dir = sys.argv[2]\n    convert_parquet_to_tsv(input_dir, output_dir)\n"})}),"\n",(0,t.jsx)(n.p,{children:"Now run the conversion with"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"python parquet_to_tsv.py . .\n"})}),"\n",(0,t.jsx)(n.p,{children:"ClickHouse will use the TSV files, but for SigLens we'll use JSON."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'for year in {2011..2017}; do\n    for month in {01..12}; do\n        basefile="yellow_tripdata_$year-$month"\n        go run siglens/tools/sigclient/cmd/utils/converter.go --input "$basefile.tsv" --output "$basefile.json" &\n    done\ndone\nwait\n'})}),"\n",(0,t.jsx)(n.p,{children:"Finally, compress the TSV and JSON files with gzip and upload them to your AWS S3 bucket.\nI ingested the TSV and JSON files into separte directories to make it easier to download all of one type."}),"\n",(0,t.jsx)(n.h2,{id:"benchmark-siglens",children:"Benchmark SigLens"}),"\n",(0,t.jsx)(n.p,{children:"You'll want three terminals. Terminal 1 will run SigLens, Terminal 2 will do some setup and view the logs, and Terminal 3 will send the queries. Terminal 3 can run in your local machine if you setup the server to accept HTTP traffic, but Terminals 1 and 2 should be on the server. Start with Terminal 1."}),"\n",(0,t.jsx)(n.h3,{id:"install-go",children:"Install Go"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install golang -y\n"})}),"\n",(0,t.jsx)(n.p,{children:"If prompted to restart some daemons, you can restart the recommended daemons."}),"\n",(0,t.jsx)(n.h3,{id:"clone-siglens",children:"Clone SigLens"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/siglens/siglens.git\ncd siglens\n"})}),"\n",(0,t.jsx)(n.h3,{id:"enable-agileaggs",children:"Enable AgileAggs"}),"\n",(0,t.jsxs)(n.p,{children:["Open ",(0,t.jsx)(n.code,{children:"server.yaml"})," and add these settings:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"agileAggsEnabled: true\npqsEnabled: true\n"})}),"\n",(0,t.jsx)(n.h3,{id:"start-siglens",children:"Start SigLens"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo go run cmd/siglens/main.go --config server.yaml\n"})}),"\n",(0,t.jsx)(n.p,{children:"Wait until SigLens is running. You'll see these lines in the terminal once it's up:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"INFO[2023-12-06 18:10:38] Extracting config from configFile: server.yaml\nINFO[2023-12-06 18:10:38] Defaulting to 2160hrs (90 days) of retention...\nINFO[2023-12-06 18:10:38] ----- Siglens server type SingleNode starting up -----\nINFO[2023-12-06 18:10:38] ----- Siglens Ingestion server starting on 0.0.0.0:8081 -----\nINFO[2023-12-06 18:10:38] ----- Siglens Query server starting on 0.0.0.0:5122 -----\nINFO[2023-12-06 18:10:38] ----- Siglens UI starting on 0.0.0.0:5122 -----\n"})}),"\n",(0,t.jsx)(n.h3,{id:"setup-pqs",children:"Setup PQS"}),"\n",(0,t.jsx)(n.p,{children:"Switch to Terminal 2 and run the following:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl -X POST -d \'{\n    "tableName": "trips",\n    "groupByColumns": ["airport_fee", "passenger_count", "PULocationID", "trip_distance"],\n    "measureColumns": ["total_amount"]\n}\' http://localhost:5122/api/pqs/aggs\necho ""\n'})}),"\n",(0,t.jsx)(n.p,{children:"You should get this response:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{"message":"All OK","status":200}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"setup-an-ingestion-script",children:"Setup an ingestion script"}),"\n",(0,t.jsxs)(n.p,{children:["In Terminal 2 run ",(0,t.jsx)(n.code,{children:"cd /mnt/nvme1n1/siglens/tools/sigclient"})," and then save the following into ingester.py"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import subprocess\nimport sys\n\n\ndef ingest(filename, batch_size=100):\n    # Determine the total number of lines in the file\n    total_lines = sum(1 for _ in open(filename, "r"))\n\n    lines = []\n    with open(filename, \'r\') as f:\n        for i, line in enumerate(f):\n            lines.append(line)\n\n            if len(lines) >= batch_size:\n                print(f"\\rProcessing... {((i + 1) / total_lines) * 100:.2f}%", end=\'\')\n                ingest_lines(lines)\n                lines = []\n    if lines:\n        ingest_lines(lines)\n        print(f"\\rProcessing... 100.00%")\n\n\ndef ingest_lines(lines):\n    index_data = \'{"index": {"_index": "trips", "_type": "_doc"}}\'\n    data = \'\'\n    for line in lines:\n        data += index_data + \'\\n\' + line\n\n    # Prepare the curl command\n    curl_command = [\n        "curl",\n        "-s",\n        "-o", "/dev/null",\n        "http://localhost:8081/elastic/_bulk",\n        "-X", "POST",\n        "-H", "Authorization: Bearer ",\n        "-H", "Content-Type: application/json",\n        "--data-binary", data\n    ]\n\n    # Execute the curl command\n    process = subprocess.run(curl_command, capture_output=False, text=False)\n    if process.stderr:\n        print("Error:", process.stderr)\n\n\nif __name__ == "__main__":\n    ingest(sys.argv[1])\n'})}),"\n",(0,t.jsx)(n.h3,{id:"ingest-the-data-into-siglens",children:"Ingest the data into SigLens"}),"\n",(0,t.jsx)(n.p,{children:"Make a dataset directory inside sigclient."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkdir dataset\n"})}),"\n",(0,t.jsx)(n.p,{children:"Run the following script to download, decompress, and ingest the data into SigLens."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'for year in {2011..2017}; do\n    for month in {01..12}; do\n        {\n            basefile="yellow_tripdata_$year-$month"\n\n            aws s3 cp s3://your-bucket/nyc-taxi-benchmark-data/json/$basefile.json.gz dataset/\n            gunzip dataset/$basefile.json.gz\n            python3 ingester.py dataset/$basefile.json\n        } &\n    done\n    wait\ndone\n'})}),"\n",(0,t.jsx)(n.h3,{id:"restart-siglens",children:"Restart SigLens"}),"\n",(0,t.jsx)(n.p,{children:"This step is to ensure that SigLens flushes all the ingested data. Simply Ctrl-C the process in Terminal 1 and restart it with"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo go run cmd/siglens/main.go --config server.yaml\n"})}),"\n",(0,t.jsx)(n.h3,{id:"view-logs",children:"View Logs"}),"\n",(0,t.jsx)(n.p,{children:"In terminal 2, run:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd /mnt/nvme1n1/siglens\nsudo tail -f siglens.log\n"})}),"\n",(0,t.jsx)(n.h3,{id:"run-the-queries-in-siglens",children:"Run the Queries in SigLens"}),"\n",(0,t.jsxs)(n.p,{children:["Run the following in Terminal 3.\nIf Terminal 3 is on your local machine, make sure to replace ",(0,t.jsx)(n.code,{children:"localhost"})," with the IP of the server.\nYou can remove the ",(0,t.jsx)(n.code,{children:" | python3 -m json.tool"})," if you want, it just formats the JSON response.\nCheck the log file ",(0,t.jsx)(n.code,{children:"siglens/siglens.log"})," for the query times."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl -X POST -d \'{\n    "searchText": "SELECT airport_fee, count(*) FROM trips GROUP BY airport_fee",\n    "index": "trips",\n    "startEpoch": "now-24h",\n    "endEpoch": "now",\n    "queryLanguage": "SQL"\n}\' http://localhost:5122/api/search | python3 -m json.tool\n\ncurl -X POST -d \'{\n    "searchText": "SELECT passenger_count, avg(total_amount) FROM trips GROUP BY passenger_count",\n    "index": "trips",\n    "startEpoch": "now-24h",\n    "endEpoch": "now",\n    "queryLanguage": "SQL"\n}\' http://localhost:5122/api/search | python3 -m json.tool\n\ncurl -X POST -d \'{\n    "searchText": "SELECT passenger_count, PULocationID, count(*) FROM trips GROUP BY passenger_count, PULocationID",\n    "index": "trips",\n    "startEpoch": "now-24h",\n    "endEpoch": "now",\n    "queryLanguage": "SQL"\n}\' http://localhost:5122/api/search | python3 -m json.tool\n\ncurl -X POST -d \'{\n    "searchText": "SELECT passenger_count, PULocationID, trip_distance, count(*) FROM trips GROUP BY passenger_count, PULocationID, trip_distance",\n    "index": "trips",\n    "startEpoch": "now-24h",\n    "endEpoch": "now",\n    "queryLanguage": "SQL"\n}\' http://localhost:5122/api/search | python3 -m json.tool\n'})}),"\n",(0,t.jsx)(n.h2,{id:"benchmark-clickhouse",children:"Benchmark ClickHouse"}),"\n",(0,t.jsx)(n.h3,{id:"install-clickhouse",children:"Install ClickHouse"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Prepare to install ClickHouse\nsudo apt-get install -y apt-transport-https ca-certificates dirmngr\nGNUPGHOME=$(mktemp -d)\nsudo GNUPGHOME="$GNUPGHOME" gpg --no-default-keyring --keyring /usr/share/keyrings/clickhouse-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 8919F6BD2B48D754\nsudo rm -r "$GNUPGHOME"\nsudo chmod +r /usr/share/keyrings/clickhouse-keyring.gpg\n\necho "deb [signed-by=/usr/share/keyrings/clickhouse-keyring.gpg] https://packages.clickhouse.com/deb stable main" | sudo tee \\\n    /etc/apt/sources.list.d/clickhouse.list\nsudo apt-get update\n\n# Install ClickHouse server and client\nsudo apt-get install -y clickhouse-server clickhouse-client\n'})}),"\n",(0,t.jsxs)(n.p,{children:["You should get the prompt ",(0,t.jsx)(n.code,{children:"Enter password for default user:"}),".\nEither create a pasword or just press enter to have no password."]}),"\n",(0,t.jsx)(n.h3,{id:"configure-the-clickhouse-data-folder",children:"Configure the ClickHouse data folder"}),"\n",(0,t.jsx)(n.p,{children:"This is an optional step to specify where ClickHouse should store its data.\nI did this during my testing so that both ClickHouse and SigLens would use the 3.5 TB storage space."}),"\n",(0,t.jsxs)(n.p,{children:["Use ",(0,t.jsx)(n.code,{children:"sudo vim /etc/clickhouse-server/config.xml"})," to change the line\n",(0,t.jsx)(n.code,{children:"<path>/var/lib/clickhouse/</path>"})," to ",(0,t.jsx)(n.code,{children:"<path>/mnt/nvme1n1/clickhouse/</path>"})]}),"\n",(0,t.jsx)(n.h3,{id:"run-clickhouse",children:"Run ClickHouse"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo service clickhouse-server start\nclickhouse-client\n"})}),"\n",(0,t.jsx)(n.h3,{id:"make-the-clickhouse-table",children:"Make the ClickHouse Table"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"CREATE TABLE trips (\n    VendorID Int32,\n    tpep_pickup_datetime DateTime,\n    tpep_dropoff_datetime DateTime,\n    passenger_count Int32,\n    trip_distance Float32,\n    RatecodeID Int32,\n    store_and_fwd_flag FixedString(1),\n    PULocationID Int32,\n    DOLocationID Int32,\n    payment_type FixedString(3),\n    fare_amount Float32,\n    extra Float32,\n    mta_tax Float32,\n    tip_amount Float32,\n    tolls_amount Float32,\n    improvement_surcharge Float32,\n    total_amount Float32,\n    congestion_surcharge Float32,\n    airport_fee Float32)\nENGINE = MergeTree()\nORDER BY (tpep_pickup_datetime)\nSETTINGS index_granularity=8192\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ingest-the-data",children:"Ingest the Data"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"INSERT INTO trips\nSELECT\n    VendorID,\n    tpep_pickup_datetime,\n    tpep_dropoff_datetime,\n    passenger_count,\n    trip_distance,\n    RatecodeID,\n    store_and_fwd_flag,\n    PULocationID,\n    DOLocationID,\n    payment_type,\n    fare_amount,\n    extra,\n    mta_tax,\n    tip_amount,\n    tolls_amount,\n    improvement_surcharge,\n    total_amount,\n    congestion_surcharge,\n    airport_fee\nFROM s3(\n    's3://your-bucket/nyc-taxi-benchmark-data/tsv/yellow_tripdata_{2011..2017}-{01..12}.tsv.gz',\n    'your_aws_access_key_id',\n    'your_aws_secret_access_key',\n    'TabSeparatedWithNames'\n);\n"})}),"\n",(0,t.jsx)(n.h3,{id:"run-the-queries-in-clickhouse",children:"Run the Queries in ClickHouse"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"# Query 1\nSELECT airport_fee, count(*) FROM trips GROUP BY airport_fee\n\n# Query 2\nSELECT passenger_count, avg(total_amount) FROM trips GROUP BY passenger_count\n\n# Query 3\nSELECT passenger_count, PULocationID, count(*) FROM trips GROUP BY passenger_count, PULocationID\n\n# Query 4\nSELECT passenger_count, PULocationID, trip_distance, count(*)\nFROM trips\nGROUP BY passenger_count, PULocationID, trip_distance\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},1151:(e,n,s)=>{s.d(n,{Z:()=>r,a:()=>o});var t=s(7294);const i={},a=t.createContext(i);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);